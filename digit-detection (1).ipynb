{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"},{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-26T12:30:29.324523Z","iopub.execute_input":"2024-02-26T12:30:29.325003Z","iopub.status.idle":"2024-02-26T12:30:30.018853Z","shell.execute_reply.started":"2024-02-26T12:30:29.324970Z","shell.execute_reply":"2024-02-26T12:30:30.017427Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchvision","metadata":{"execution":{"iopub.status.busy":"2024-02-26T12:30:31.266473Z","iopub.execute_input":"2024-02-26T12:30:31.267995Z","iopub.status.idle":"2024-02-26T12:30:48.901687Z","shell.execute_reply.started":"2024-02-26T12:30:31.267946Z","shell.execute_reply":"2024-02-26T12:30:48.900482Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch==2.1.2 in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.1.2+cpu)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision) (2023.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch,torchvision\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-02-26T12:30:49.305648Z","iopub.execute_input":"2024-02-26T12:30:49.306145Z","iopub.status.idle":"2024-02-26T12:30:49.313602Z","shell.execute_reply.started":"2024-02-26T12:30:49.306099Z","shell.execute_reply":"2024-02-26T12:30:49.312402Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset=datasets.MNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\ntest_dataset=datasets.MNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T12:30:59.695943Z","iopub.execute_input":"2024-02-26T12:30:59.696472Z","iopub.status.idle":"2024-02-26T12:31:00.742829Z","shell.execute_reply.started":"2024-02-26T12:30:59.696426Z","shell.execute_reply":"2024-02-26T12:31:00.741501Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 116661507.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 31869427.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 38196471.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 10818017.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=64\n\ntrain_dl=DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\ntest_dl=DataLoader(\n    dataset=test_dataset,\n    batch_size=batch_size, \n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T12:31:10.212140Z","iopub.execute_input":"2024-02-26T12:31:10.212612Z","iopub.status.idle":"2024-02-26T12:31:10.220321Z","shell.execute_reply.started":"2024-02-26T12:31:10.212577Z","shell.execute_reply":"2024-02-26T12:31:10.218931Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i,j in train_dl:\n    print(i, j)\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class mymodel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.inh1=nn.Linear(in_features=784, out_features=512)\n        self.relu=nn.ReLU()\n        self.bn1=nn.BatchNorm1d(num_features=512)\n        self.h2=nn.Linear(in_features=512, out_features=256)\n        self.bn2=nn.BatchNorm1d(num_features=256)\n        self.h3=nn.Linear(in_features=256, out_features=128)\n        self.bn3=nn.BatchNorm1d(num_features=128)\n        self.h4=nn.Linear(in_features=128, out_features=64)\n        self.bn4=nn.BatchNorm1d(num_features=64)\n        self.h5=nn.Linear(in_features=64, out_features=32)\n        self.bn5=nn.BatchNorm1d(num_features=32)\n        self.output=nn.Linear(in_features=32, out_features=10)\n        self.bn6=nn.BatchNorm1d(num_features=10)\n        self.flat=nn.Flatten()\n        self.d1=nn.Linear(in_features=512*512, out_features=10)\n        \n    def forward(self, x):\n        x=self.inh1(x)\n        x=self.bn1(x)\n        x=self.relu(x)\n        x=self.h2(x)\n        x=self.bn2(x)\n        x=self.relu(x)\n        x=self.h3(x)\n        x=self.bn3(x)\n        x=self.relu(x)\n        x=self.h4(x)\n        x=self.bn4(x)\n        x=self.relu(x)\n        x=self.h5(x)\n        x=self.bn5(x)\n        x=self.relu(x)\n        x=self.output(x)\n        output=self.bn6(x)\n        return output\n    \ndef train_one_epoch(dataloader, model, loss_fn, optimizer):\n    model.train()\n    track_loss=0\n    num_correct=0\n    for i,(img, labels) in enumerate(dataloader):\n        imgs=torch.reshape(img, shape=[-1, 784])\n        labels=labels\n        pred=model(imgs)\n#         print(pred.shape, labels.shape)\n        loss=loss_fn(pred, labels)\n        track_loss+=loss.item()\n        num_correct+=(torch.argmax(pred, dim=1)==labels).type(torch.float).sum().item()\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    if i%100==0:\n        running_loss=round(track_loss/(i+1),2)\n        running_acc=round((num_correct/((i+1)*batch_size))*100,2)\n        print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n    epoch_loss=track_loss/len(dataloader) #can be slightly inaccurate\n    epoch_acc=(num_correct/len(dataloader.dataset))*100    \n    return round(epoch_loss,2), round(epoch_acc,2)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:31:41.470123Z","iopub.execute_input":"2024-02-26T13:31:41.470594Z","iopub.status.idle":"2024-02-26T13:31:41.493326Z","shell.execute_reply.started":"2024-02-26T13:31:41.470559Z","shell.execute_reply":"2024-02-26T13:31:41.492219Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"model=mymodel()\nmodel=model\nloss_fn=nn.CrossEntropyLoss()\nlr=0.001\n#optimizer=torch.optim.SGD(params=model.parameters(), lr=lr)\noptimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\nn_epochs=5\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_acc=train_one_epoch(train_dl,model,loss_fn,optimizer)\n#     print(j)\n#     val_epoch_loss, val_epoch_acc=eval_one_epoch(test_dl,model,loss_fn)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n#     print(\"Inference:\", \"Epoch Loss:\", val_epoch_loss, \"Epoch Accuracy:\", val_epoch_acc)\n    print(\"--------------------------------------------------\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:41:29.947446Z","iopub.execute_input":"2024-02-26T14:41:29.947913Z","iopub.status.idle":"2024-02-26T14:41:30.432818Z","shell.execute_reply.started":"2024-02-26T14:41:29.947878Z","shell.execute_reply":"2024-02-26T14:41:30.431308Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mmymodel\u001b[49m()\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mmodel\n\u001b[1;32m      3\u001b[0m loss_fn\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n","\u001b[0;31mNameError\u001b[0m: name 'mymodel' is not defined"],"ename":"NameError","evalue":"name 'mymodel' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport torch\nimport torch.nn as nn\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)#28-2\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)#13-2\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)#5-2\n        self.pool = nn.MaxPool2d(2, 2)\n        self.out = nn.ReLU()\n        self.dropout=nn.Dropout(0.25)\n        self.fc2 = nn.Linear(128, 10)\n        self.fl=nn.Flatten()\n    def forward(self, x):\n        x = self.dropout(self.pool(self.out(self.conv1(x))))\n        x = self.dropout(self.pool(self.out(self.conv2(x))))\n        x = self.dropout(self.pool(self.out(self.conv3(x))))\n        x = self.fl(x)\n        x = self.fc2(x)\n        return x\n\n# Create an instance of the CNN model\ndef train_one_epoch2(dataloader, model, loss_fn, optimizer):\n    model.train()\n    track_loss=0\n    num_correct=0\n    for j,(img, labels) in enumerate(dataloader):\n        labels=labels\n        pred=model(img)\n        loss=loss_fn(pred, labels)\n        track_loss+=loss.item()\n        num_correct+=(torch.argmax(pred, dim=1)==labels).type(torch.float).sum().item()\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    if i%100==0:\n        running_loss=round(track_loss/(i+1),2)\n        running_acc=round((num_correct/((i+1)*batch_size))*100,2)\n        print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n    epoch_loss=track_loss/len(dataloader) #can be slightly inaccurate\n    epoch_acc=(num_correct/len(dataloader.dataset))*100    \n    return round(epoch_loss,2), round(epoch_acc,2)\n\ndef eval_one(dataloader, model):\n    track_loss=0\n    num_correct=0\n    for j,(img, labels) in enumerate(dataloader):\n        labels=labels\n        pred=model(img)\n        loss=loss_fn(pred, labels)\n        track_loss+=loss.item()\n        num_correct+=(torch.argmax(pred, dim=1)==labels).type(torch.float).sum().item()\n        \n    if i%100==0:\n        running_loss=round(track_loss/(i+1),2)\n        running_acc=round((num_correct/((i+1)*batch_size))*100,2)\n        print(\"Batch:\", i+1, \"/\",len(dataloader), \"Validation Loss:\",running_loss, \"Validation Accuracy:\",running_acc)\n    epoch_loss=track_loss/len(dataloader) #can be slightly inaccurate\n    epoch_acc=(num_correct/len(dataloader.dataset))*100    \n    return round(epoch_loss,2), round(epoch_acc,2)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:13:38.043668Z","iopub.execute_input":"2024-02-26T14:13:38.044107Z","iopub.status.idle":"2024-02-26T14:13:38.074352Z","shell.execute_reply.started":"2024-02-26T14:13:38.044073Z","shell.execute_reply":"2024-02-26T14:13:38.073141Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"model=CNN()\nloss_fn=nn.CrossEntropyLoss()\nlr=0.001\n#optimizer=torch.optim.SGD(params=model.parameters(), lr=lr)\noptimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\nn_epochs=5\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_acc=train_one_epoch2(train_dl,model,loss_fn,optimizer)\n#     print(j)\n    val_epoch_loss, val_epoch_acc=eval_one_epoch(test_dl,model,loss_fn)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"Validation:\", \"Epoch Loss:\", val_epoch_loss, \"Epoch Accuracy:\", val_epoch_acc)\n    print(\"--------------------------------------------------\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:19:14.912713Z","iopub.execute_input":"2024-02-26T14:19:14.913190Z","iopub.status.idle":"2024-02-26T14:23:09.385171Z","shell.execute_reply.started":"2024-02-26T14:19:14.913134Z","shell.execute_reply":"2024-02-26T14:23:09.383764Z"},"trusted":true},"execution_count":190,"outputs":[{"name":"stdout","text":"Epoch No: 1\nBatch: 1 / 938 Running Loss: 359.62 Running Accuracy: 82357.81\nBatch: 1 / 157 Validation Loss: 22.08 Validation Accuracy: 14965.62\nTraining: Epoch Loss: 0.38 Epoch Accuracy: 87.85\nValidation: Epoch Loss: 0.14 Epoch Accuracy: 95.78\n--------------------------------------------------\nEpoch No: 2\nTraining: Epoch Loss: 0.14 Epoch Accuracy: 95.83\nValidation: Epoch Loss: 0.12 Epoch Accuracy: 96.68\n--------------------------------------------------\nEpoch No: 3\nTraining: Epoch Loss: 0.11 Epoch Accuracy: 96.66\nValidation: Epoch Loss: 0.1 Epoch Accuracy: 96.54\n--------------------------------------------------\nEpoch No: 4\nTraining: Epoch Loss: 0.09 Epoch Accuracy: 97.24\nValidation: Epoch Loss: 0.1 Epoch Accuracy: 97.3\n--------------------------------------------------\nEpoch No: 5\nTraining: Epoch Loss: 0.08 Epoch Accuracy: 97.56\nValidation: Epoch Loss: 0.08 Epoch Accuracy: 97.69\n--------------------------------------------------\n","output_type":"stream"}]}]}